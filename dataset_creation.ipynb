{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yburt\\anaconda3\\envs\\env_scrapping\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets, Value\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_source_col(data, name_col, value):\n",
    "    new_col = [value] * len(data)\n",
    "    data = data.add_column(name_col, new_col) \n",
    "    return data\n",
    "\n",
    "def print_value_count(data, column_s):\n",
    "    temp=pd.DataFrame(data[column_s], columns=[column_s])\n",
    "    print(temp.groupby(column_s).value_counts())\n",
    "\n",
    "def explode_answer(x):\n",
    "    x[\"answers\"] = x[\"answers\"].get(\"text\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset summary\n",
    "- None\n",
    "\n",
    "### Supported Tasks and Leaderboards\n",
    "- No specified\n",
    "\n",
    "### Use in models\n",
    "- nol2pro (fine-tuned version of t5-small on the yahoo_answers_qa dataset.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = load_dataset(\"yahoo_answers_qa\", split=\"train\")\n",
    "dataset1_b = add_source_col(dataset1, \"which_data\", \"train\")\n",
    "dataset1_b = dataset1_b.filter(lambda x: (x['main_category'] == 'Business & Finance') or (x[\"main_category\"] ==\"Computers & Internet\"))\n",
    "dataset1_b = add_source_col(dataset1_b, \"source\", \"yahoo_answers_qa\")\n",
    "dataset1_b = add_source_col(dataset1_b, \"type\", \"general questions finance\")\n",
    "dataset1_b = add_source_col(dataset1_b, \"task\", [\"question answering tasks\"])\n",
    "dataset1_b = add_source_col(dataset1_b, \"model\", \"nol2pro\")\n",
    "\n",
    "dataset1_b1= add_source_col(dataset1_b, \"context\", \"None\")\n",
    "dataset1_b1=dataset1_b1.rename_columns({\"context\": \"context\", 'question': 'question', \"answer\": \"answer\", \"main_category\": \"question_category\"})\n",
    "dataset1_b1= dataset1_b1.remove_columns([\"nbestanswers\", \"id\"])\n",
    "\n",
    "dataset1_b2 = dataset1_b1.map(lambda x: {\"question_category\": [x[\"question_category\"]]})\n",
    "dataset1_f = dataset1_b2.map(lambda x: {\"answer\": [x[\"answer\"]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Summary\n",
    "\n",
    "This dataset comes originally from kaggle. It was originally split into three tables (CSV files) (Questions, Answers, and Tags) now merged into a single table. Each row corresponds to a pair (question-answer) and their associated tags.\n",
    "\n",
    "The dataset contains all questions asked between August 2, 2008 and Ocotober 19, 2016.\n",
    "\n",
    "### Supported Tasks and Leaderboards\n",
    "\n",
    "This might be useful for open-domain question-answering tasks. \n",
    "\n",
    "### Use in model\n",
    "\n",
    "- llama-2-7b-finetuned-python-qa_tokenizer (no more specifications)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = load_dataset(\"koutch/stackoverflow_python\")\n",
    "dataset2_b = add_source_col(dataset2.get(\"train\"), \"which_data\", \"train\")\n",
    "dataset2_b = add_source_col(dataset2_b, \"source\", \"koutch/stackoverflow_python\")\n",
    "dataset2_b = add_source_col(dataset2_b, \"type\", \"technical questions\")\n",
    "dataset2_b = add_source_col(dataset2_b, \"task\", [\"question answering tasks\"])\n",
    "dataset2_b = add_source_col(dataset2_b, \"model\", \"llama-2-7b-finetuned-python-qa_tokenizer\")\n",
    "\n",
    "dataset2_b1=dataset2_b.rename_columns({'title': \"context\", 'question_body': 'question', \"answer_body\": \"answer\", \"tags\": \"question_category\"})\n",
    "dataset2_b1= dataset2_b1.remove_columns([\"question_score\", \"question_id\", \"question_date\", \"answer_id\", \"answer_score\", \"answer_date\"])\n",
    "\n",
    "dataset2_f = dataset2_b1.map(lambda x: {\"answer\": [x[\"answer\"]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQuAD-fr:\n",
    "\n",
    "- a translated version of the Stanford Question Answering Dataset (SQuAD) into French obtained through automatic translation of the English dataset\n",
    "- a reading comprehension dataset, consisting of approximately 90K factoid questions on Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage serves as a means of data augmentation on FQuAD and PIAF benchmarks\n",
    "\n",
    "\n",
    "#### Supported Tasks and Leaderboards\n",
    "closed-domain-qa, text-retrieval: This dataset is intended to be used for closed-domain-qa, but can also be used for information retrieval tasks.\n",
    "\n",
    "### Use in models\n",
    "\n",
    "- No communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = load_dataset(\"qwant/squad_fr\")\n",
    "dataset3 = dataset3.map(explode_answer)\n",
    "\n",
    "dataset3_b = add_source_col(dataset3.get(\"train\"), \"which_data\", \"train\")\n",
    "dataset3_b = add_source_col(dataset3_b, \"source\", \"qwant/squad_fr\")\n",
    "dataset3_b = add_source_col(dataset3_b, \"type\", \"general questions\")\n",
    "dataset3_b = add_source_col(dataset3_b, \"task\", [\"question answering tasks\", \"text-retrieval\"])\n",
    "dataset3_b = add_source_col(dataset3_b, \"model\", \"no communication\")\n",
    "\n",
    "dataset3_b=dataset3_b.filter(lambda example: (example['title']== 'Energy')\n",
    "                 or (example[\"title\"]==\"Communication\")\n",
    "                 or (example[\"title\"]==\"Computer\")\n",
    "                 or (example[\"title\"]==\"Computer_security\")\n",
    "                 or (example[\"title\"]==\"Economic_inequality\")\n",
    "                 or (example[\"title\"]==\"European_Union_law\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3_t= add_source_col(dataset3.get(\"validation\"), \"which_data\", \"validation\")\n",
    "dataset3_t = add_source_col(dataset3_t, \"source\", \"qwant/squad_fr\")\n",
    "dataset3_t = add_source_col(dataset3_t, \"type\", \"general questions\")\n",
    "dataset3_t = add_source_col(dataset3_t, \"task\", [\"question answering tasks\", \"text-retrieval\"])\n",
    "dataset3_t = add_source_col(dataset3_t, \"model\", \"no communication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3_c = concatenate_datasets([dataset3_t, dataset3_b])\n",
    "dataset3_c = add_source_col(dataset3_c, \"question_category\", \"None\")\n",
    "dataset3_c=dataset3_c.rename_columns({\"context\": \"context\", 'question': 'question', \"answers\": \"answer\"})\n",
    "dataset3_c= dataset3_c.remove_columns([\"title\", \"id\"])\n",
    "\n",
    "dataset3_f = dataset3_c.map(lambda x: {\"question_category\": [x[\"question_category\"]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------\n",
    "### Dataset Summary\n",
    "We are thrilled to announce the release of the OpenOrca dataset! This rich collection of augmented FLAN data aligns, as best as possible, with the distributions outlined in the Orca paper. It has been instrumental in generating high-performing model checkpoints and serves as a valuable resource for all NLP researchers and developers!\n",
    "\n",
    "### Supported Tasks and Leaderboards\n",
    "\n",
    "This dataset supports a range of tasks including language modeling, text generation, and text augmentation. It has been instrumental in the generation of multiple high-performing model checkpoints which have exhibited exceptional performance in our unit testing. \n",
    "\n",
    "### Use in model\n",
    "\n",
    "- Fine tuning on top of Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset4 = load_dataset(\"Open-Orca/OpenOrca\")\n",
    "dataset4_b = add_source_col(dataset4.get(\"train\"), \"which_data\", \"train\")\n",
    "dataset4_b = add_source_col(dataset4_b, \"source\", \"Open-Orca/OpenOrca\")\n",
    "dataset4_b = add_source_col(dataset4_b, \"type\", \"general questions\")\n",
    "dataset4_b = add_source_col(dataset4_b, \"task\", [\"language modeling\", \"text generation\", \"text augmentation\"])\n",
    "dataset4_b = add_source_col(dataset4_b, \"model\", \"fine tuned mistral 7B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset4_b1=dataset4_b.rename_columns({\"system_prompt\": \"context\", 'question': 'question', \"response\": \"answer\"})\n",
    "dataset4_b1= dataset4_b1.remove_columns([\"id\"])\n",
    "dataset4_b1 = add_source_col(dataset4_b1, \"question_category\", \"None\")\n",
    "\n",
    "dataset4_b2 = dataset4_b1.map(lambda x: {\"question_category\": [x[\"question_category\"]]})\n",
    "dataset4_f = dataset4_b2.map(lambda x: {\"answer\": [x[\"answer\"]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------\n",
    "### Dataset Summary\n",
    "\n",
    "FinTalk-19k is a domain-specific dataset designed for the fine-tuning of Large Language Models (LLMs) with a focus on financial conversations. Extracted from public Reddit conversations, this dataset is tagged with categories like \"Personal Finance\", \"Financial Information\", and \"Public Sentiment\". It consists of more than 19,000 entries, each representing a conversation about financial topics.\n",
    "\n",
    "### Supported Tasks and Leaderboards\n",
    "\n",
    "- language-modeling: The dataset can be used to train models for language modeling in the context of financial discussions.\n",
    "- text-generation: Suitable for generating responses in financial conversations.\n",
    "\n",
    "### Languages\n",
    "\n",
    "The dataset is primarily in English.\n",
    "\n",
    "### Sources: from REDDIT\n",
    "\n",
    "### Use in model\n",
    "- No communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset5 = load_dataset(\"ceadar-ie/FinTalk-19k\")\n",
    "dataset5_b = add_source_col(dataset5.get(\"train\"), \"which_data\", \"train\")\n",
    "dataset5_b = add_source_col(dataset5_b, \"source\", \"ceadar-ie/FinTalk-19k\")\n",
    "dataset5_b = add_source_col(dataset5_b, \"type\", \"general financial questions\")\n",
    "dataset5_b = add_source_col(dataset5_b, \"task\", [\"question answering tasks\"])\n",
    "dataset5_b = add_source_col(dataset5_b, \"model\", \"no communication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset5_b1=dataset5_b.rename_columns({\"context\": \"context\", 'instruction': 'question', \"response\": \"answer\", \"tag\":\"question_category\"})\n",
    "dataset5_b2 = dataset5_b1.map(lambda x: {\"question_category\": [x[\"question_category\"]]})\n",
    "dataset5_f = dataset5_b2.map(lambda x: {\"answer\": [x[\"answer\"]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------\n",
    "### Dataset Summary\n",
    "\n",
    "The x-stance dataset contains more than 150 political questions, and 67k comments written by candidates on those questions. The comments are partly German, partly French and Italian. The data have been extracted from the Swiss voting advice platform Smartvote.\n",
    "\n",
    "### Supported Tasks and Leaderboards\n",
    "\n",
    "- fast checking\n",
    "\n",
    "### Model in use\n",
    "-  mDeBERTa-v3-base-tasksource-nli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset6 = load_dataset(\"strombergnlp/x-stance\", \"fr\")\n",
    "dataset6_b = add_source_col(dataset6.get(\"validation\"), \"which_data\", \"validation\")\n",
    "dataset6_b = add_source_col(dataset6_b, \"source\", \"strombergnlp/x-stance\")\n",
    "dataset6_b = add_source_col(dataset6_b, \"type\", \"political questions\")\n",
    "dataset6_b = add_source_col(dataset6_b, \"task\", [\"question answering tasks\"])\n",
    "dataset6_b = add_source_col(dataset6_b, \"model\", \"mDeBERTa-v3-base-tasksource-nli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset6_t = add_source_col(dataset6.get(\"test\"), \"which_data\", \"test\")\n",
    "dataset6_t = add_source_col(dataset6_t, \"source\", \"strombergnlp/x-stance\")\n",
    "dataset6_t = add_source_col(dataset6_t, \"type\", \"political questions\")\n",
    "dataset6_t = add_source_col(dataset6_t, \"task\", [\"question answering tasks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset6_q = add_source_col(dataset6.get(\"train\"), \"which_data\", \"train\")\n",
    "dataset6_q = add_source_col(dataset6_q, \"source\", \"strombergnlp/x-stance\")\n",
    "dataset6_q = add_source_col(dataset6_q, \"type\", \"political questions\")\n",
    "dataset6_q = add_source_col(dataset6_q, \"task\", [\"question answering tasks\"])\n",
    "dataset6_q = add_source_col(dataset6_q, \"model\", \"mDeBERTa-v3-base-tasksource-nli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset6_c = concatenate_datasets([dataset6_q, dataset6_t, dataset6_b])\n",
    "dataset6_c = add_source_col(dataset6_c, \"question_category\", \"None\")\n",
    "dataset6_c = dataset6_c.rename_columns({'label': \"context\", 'question': 'question', \"comment\": \"answer\"})\n",
    "dataset6_c = dataset6_c.remove_columns([\"id\"])\n",
    "\n",
    "dataset6_c1 = dataset6_c.map(lambda x: {\"question_category\": [x[\"question_category\"]]})\n",
    "dataset6_c2 = dataset6_c1.map(lambda x: {\"answer\": [x[\"answer\"]]})\n",
    "dataset6_f = dataset6_c2.cast_column('context', Value(dtype='string', id=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_performances_evaluation=concatenate_datasets([dataset4_f, dataset5_f, dataset6_f, dataset3_f, dataset2_f, dataset1_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format:   0%|          | 0/5291 [00:00<?, ?ba/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 5291/5291 [24:51<00:00,  3.55ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10020426893"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_performances_evaluation.to_csv(\"C:\\\\Users\\\\yburt\\\\Documents\\\\Web_scrapping\\\\data_perf_eval.csv\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"C:\\\\Users\\\\yburt\\\\Documents\\\\Web_scrapping\\\\data_perf_eval.csv\", sep=\"|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_scrapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
